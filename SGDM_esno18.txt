Namespace(activation='relu', arch='resnet18', cuda='1', optimizer='SGDM', root='D:/qpsk_awgn_sps8_esno18.dat')
ResNet(
  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (fc): Linear(in_features=512, out_features=2, bias=True)
)
loading data
  epoch    accuracy    train_loss    valid_loss    cp       dur
-------  ----------  ------------  ------------  ----  --------
      1      0.9931        0.0885        0.0179     +  149.4403
      2      0.9937        0.0058        0.0178     +  147.9352
      3      0.9959        0.0031        0.0124     +  148.2394
      4      0.9983        0.0019        0.0047     +  148.3485
      5      0.9982        0.0012        0.0051        146.7833
      6      0.9986        0.0009        0.0042     +  137.0311
      7      0.9983        0.0005        0.0050        136.8029
      8      0.9979        0.0005        0.0060        136.6978
      9      0.9987        0.0003        0.0038     +  136.7228
     10      0.9983        0.0002        0.0051        136.8499
     11      0.9988        0.0002        0.0036     +  136.9920
     12      0.9987        0.0002        0.0039        136.9640
     13      0.9988        0.0001        0.0036     +  136.9160
     14      0.9988        0.0001        0.0035     +  137.1702
     15      0.9989        0.0001        0.0036        136.9020
     16      0.9990        0.0001        0.0035        137.0761
     17      0.9989        0.0000        0.0033     +  137.1251
     18      0.9989        0.0000        0.0032     +  136.7228
     19      0.9989        0.0001        0.0033        137.2923
     20      0.9986        0.0001        0.0036        137.0991
     21      0.9986        0.0001        0.0039        137.0661
     22      0.9985        0.0001        0.0044        137.3233
Re-initializing optimizer because the following parameters were re-set: lr.
     23      0.9988        0.0001        0.0034        137.0371
     24      0.9988        0.0001        0.0034        137.1852
     25      0.9990        0.0000        0.0034        136.9640
     26      0.9988        0.0000        0.0032     +  136.7208
     27      0.9988        0.0000        0.0033        137.5845
     28      0.9988        0.0000        0.0033        136.7499
     29      0.9988        0.0000        0.0032        137.0781
     30      0.9989        0.0000        0.0032     +  137.2602
     31      0.9989        0.0000        0.0032     +  137.1081
     32      0.9989        0.0000        0.0031     +  137.4404
     33      0.9989        0.0000        0.0031     +  136.9400
     34      0.9990        0.0000        0.0032        137.0911
     35      0.9989        0.0000        0.0032        137.0471
     36      0.9989        0.0000        0.0031     +  137.2572
     37      0.9989        0.0000        0.0032        137.0191
     38      0.9989        0.0000        0.0032        137.3093
     39      0.9988        0.0000        0.0032        138.6938
     40      0.9990        0.0000        0.0031        137.0361
Re-initializing optimizer because the following parameters were re-set: lr.
     41      0.9990        0.0000        0.0031        137.5174
     42      0.9990        0.0000        0.0032        137.2082
     43      0.9989        0.0000        0.0032        137.4404
     44      0.9989        0.0000        0.0031        137.5054
     45      0.9988        0.0000        0.0033        137.3733
     46      0.9988        0.0000        0.0032        137.6045
     47      0.9988        0.0000        0.0032        137.1822
     48      0.9988        0.0000        0.0033        137.4614
     49      0.9990        0.0000        0.0031        137.2052
     50      0.9989        0.0000        0.0032        136.9850
     51      0.9988        0.0000        0.0034        136.8629
     52      0.9990        0.0000        0.0031        137.1081
     53      0.9988        0.0000        0.0033        136.5767
     54      0.9988        0.0000        0.0031        136.8689
     55      0.9989        0.0000        0.0031        137.2522
Stopping since valid_loss has not improved in the last 20 epochs.
Best Model State Restored
Best Confusion Matrix:
 [[100   0]
 [  0 100]]
