Namespace(activation='elu', arch='resnet18', cuda='0', optimizer='SGD', root='D:/qpsk_awgn_sps8_esno14.dat')
ResNet(
  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (fc): Linear(in_features=512, out_features=2, bias=True)
)
loading data
  epoch    accuracy    train_loss    valid_loss    cp       dur
-------  ----------  ------------  ------------  ----  --------
      1      0.9252        0.2546        0.1828     +  130.7414
      2      0.9366        0.1247        0.1612     +  124.3196
      3      0.9640        0.1003        0.0918     +  124.2445
      4      0.9667        0.0815        0.0851     +  124.2846
      5      0.9705        0.0718        0.0745     +  124.0864
      6      0.9690        0.0642        0.0810        124.3936
      7      0.9730        0.0582        0.0699     +  124.3686
      8      0.9739        0.0543        0.0682     +  124.2525
      9      0.9714        0.0512        0.0752        124.6388
     10      0.9771        0.0487        0.0620     +  124.5798
     11      0.9650        0.0461        0.0963        124.4387
     12      0.9770        0.0446        0.0616     +  124.2946
     13      0.9748        0.0424        0.0657        124.6118
     14      0.9767        0.0400        0.0604     +  124.5488
     15      0.9694        0.0395        0.0879        124.3676
     16      0.9775        0.0366        0.0616        124.2485
     17      0.9780        0.0364        0.0607        124.0874
     18      0.9718        0.0342        0.0786        123.8472
     19      0.9797        0.0329        0.0551     +  123.8723
     20      0.9794        0.0315        0.0567        123.8462
     21      0.9780        0.0297        0.0608        123.7051
     22      0.9718        0.0282        0.0816        123.7462
     23      0.9772        0.0274        0.0653        124.0844
Re-initializing optimizer because the following parameters were re-set: lr.
     24      0.9776        0.0262        0.0622        123.7722
     25      0.9809        0.0171        0.0531     +  124.1815
     26      0.9813        0.0155        0.0536        123.9443
     27      0.9816        0.0149        0.0538        124.0584
     28      0.9810        0.0146        0.0548        124.1004
     29      0.9808        0.0145        0.0546        124.1515
Re-initializing optimizer because the following parameters were re-set: lr.
     30      0.9808        0.0140        0.0552        124.2796
     31      0.9810        0.0131        0.0552        124.4687
     32      0.9810        0.0129        0.0551        123.9673
     33      0.9809        0.0126        0.0550        124.1815
     34      0.9811        0.0129        0.0552        124.2255
     35      0.9810        0.0131        0.0551        124.7229
     36      0.9809        0.0128        0.0554        124.2585
     37      0.9808        0.0130        0.0557        124.2435
     38      0.9810        0.0129        0.0554        124.2075
     39      0.9807        0.0129        0.0554        124.3436
     40      0.9807        0.0124        0.0555        124.4827
     41      0.9810        0.0126        0.0554        124.3276
     42      0.9808        0.0125        0.0553        124.5037
     43      0.9810        0.0127        0.0555        124.5518
     44      0.9808        0.0125        0.0556        124.2045
Stopping since valid_loss has not improved in the last 20 epochs.
Best Model State Restored
Best Confusion Matrix:
 [[98  2]
 [ 2 98]]
