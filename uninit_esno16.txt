Namespace(activation='uninit_param', arch='resnet18', cuda='0', optimizer='SGD', root='D:/qpsk_awgn_sps8_esno16.dat')
ResNet(
  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (fc): Linear(in_features=512, out_features=2, bias=True)
)
loading data
  epoch    accuracy    train_loss    valid_loss    cp       dur
-------  ----------  ------------  ------------  ----  --------
      1      0.9586        0.2933        0.1061     +  126.0879
      2      0.9834        0.0548        0.0463     +  124.4967
      3      0.9839        0.0344        0.0430     +  124.5127
      4      0.9882        0.0246        0.0320     +  124.7829
      5      0.9652        0.0189        0.0954        124.8690
      6      0.9885        0.0146        0.0296     +  124.7569
      7      0.9870        0.0115        0.0361        124.7859
      8      0.9852        0.0093        0.0417        124.7049
      9      0.9896        0.0072        0.0285     +  124.8350
     10      0.9902        0.0054        0.0278     +  124.5908
     11      0.9866        0.0044        0.0406        124.6969
     12      0.9906        0.0037        0.0270     +  124.6608
     13      0.9900        0.0030        0.0292        124.6388
     14      0.9895        0.0024        0.0311        124.4887
     15      0.9910        0.0020        0.0264     +  124.4637
     16      0.9906        0.0018        0.0293        124.4717
     17      0.9900        0.0016        0.0307        124.5978
     18      0.9897        0.0014        0.0313        124.3736
     19      0.9912        0.0012        0.0277        124.4797
Re-initializing optimizer because the following parameters were re-set: lr.
     20      0.9908        0.0011        0.0268        124.3376
     21      0.9911        0.0010        0.0272        124.6278
     22      0.9912        0.0009        0.0264     +  124.4627
     23      0.9910        0.0009        0.0274        124.2746
     24      0.9909        0.0009        0.0279        124.4427
     25      0.9909        0.0008        0.0263     +  124.3386
     26      0.9912        0.0008        0.0270        124.4537
     27      0.9911        0.0009        0.0264        124.6178
     28      0.9911        0.0008        0.0262     +  124.4007
     29      0.9911        0.0008        0.0274        124.3896
     30      0.9912        0.0008        0.0266        124.2616
     31      0.9911        0.0008        0.0271        124.2345
     32      0.9910        0.0008        0.0264        124.3096
Re-initializing optimizer because the following parameters were re-set: lr.
     33      0.9911        0.0008        0.0265        124.3916
     34      0.9912        0.0008        0.0269        124.4457
     35      0.9911        0.0008        0.0265        122.2230
     36      0.9911        0.0007        0.0264        121.3674
     37      0.9911        0.0007        0.0265        121.3674
     38      0.9911        0.0007        0.0265        121.2643
     39      0.9911        0.0007        0.0263        121.3114
     40      0.9913        0.0008        0.0264        121.5135
     41      0.9910        0.0008        0.0264        121.5055
     42      0.9912        0.0008        0.0268        121.6616
     43      0.9911        0.0007        0.0264        121.3164
     44      0.9911        0.0007        0.0267        121.7667
     45      0.9911        0.0007        0.0263        121.5936
     46      0.9911        0.0008        0.0264        121.7157
     47      0.9912        0.0007        0.0267        121.5565
Stopping since valid_loss has not improved in the last 20 epochs.
Best Model State Restored
Best Confusion Matrix:
 [[99  1]
 [ 1 99]]
