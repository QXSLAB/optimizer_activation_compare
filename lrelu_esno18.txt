Namespace(activation='lrelu', arch='resnet18', cuda='0', optimizer='SGD', root='D:/qpsk_awgn_sps8_esno18.dat')
ResNet(
  (conv1): Conv1d(2, 64, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (1): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace)
      (conv2): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (fc): Linear(in_features=512, out_features=2, bias=True)
)
loading data
  epoch    accuracy    train_loss    valid_loss    cp       dur
-------  ----------  ------------  ------------  ----  --------
      1      0.9787        0.3402        0.0622     +  132.6328
      2      0.9903        0.0401        0.0277     +  130.7334
      3      0.9930        0.0204        0.0196     +  129.0411
      4      0.9949        0.0133        0.0153     +  128.6078
      5      0.9953        0.0096        0.0133     +  128.3396
      6      0.9958        0.0071        0.0118     +  128.3216
      7      0.9959        0.0057        0.0117     +  128.1204
      8      0.9963        0.0045        0.0103     +  128.4166
      9      0.9963        0.0036        0.0102     +  128.1304
     10      0.9961        0.0031        0.0101     +  128.3306
     11      0.9966        0.0025        0.0092     +  128.3346
     12      0.9966        0.0022        0.0092        128.3756
     13      0.9969        0.0019        0.0088     +  128.5798
     14      0.9968        0.0018        0.0087     +  128.7679
     15      0.9969        0.0015        0.0086     +  128.4176
     16      0.9970        0.0014        0.0087        128.7429
     17      0.9970        0.0012        0.0086     +  128.8350
     18      0.9970        0.0011        0.0083     +  128.5548
     19      0.9971        0.0010        0.0082     +  128.3986
     20      0.9972        0.0010        0.0081     +  128.2675
     21      0.9971        0.0008        0.0084        128.3546
     22      0.9972        0.0008        0.0080     +  128.4267
     23      0.9972        0.0007        0.0081        128.2425
     24      0.9971        0.0007        0.0081        127.9053
     25      0.9972        0.0006        0.0081        128.3586
     26      0.9968        0.0006        0.0088        128.1274
     27      0.9972        0.0006        0.0079     +  128.2755
     28      0.9972        0.0005        0.0080        128.3106
     29      0.9975        0.0005        0.0077     +  128.4437
     30      0.9973        0.0005        0.0079        128.0614
     31      0.9973        0.0005        0.0078        128.4206
     32      0.9974        0.0005        0.0077        128.5588
     33      0.9973        0.0004        0.0079        128.4677
Re-initializing optimizer because the following parameters were re-set: lr.
     34      0.9973        0.0004        0.0080        128.2045
     35      0.9973        0.0004        0.0079        128.0984
     36      0.9974        0.0004        0.0078        128.0264
     37      0.9973        0.0004        0.0078        128.3756
     38      0.9974        0.0004        0.0078        128.2305
     39      0.9973        0.0004        0.0078        128.1885
     40      0.9974        0.0004        0.0078        128.4877
     41      0.9972        0.0003        0.0080        128.5047
     42      0.9974        0.0004        0.0078        128.4006
     43      0.9973        0.0003        0.0079        128.5467
     44      0.9974        0.0003        0.0078        128.6708
     45      0.9971        0.0003        0.0081        128.5047
     46      0.9974        0.0004        0.0079        128.4637
     47      0.9973        0.0004        0.0079        128.3876
     48      0.9973        0.0003        0.0079        128.5187
Stopping since valid_loss has not improved in the last 20 epochs.
Best Model State Restored
Best Confusion Matrix:
 [[100   0]
 [  0 100]]
